minWorkers: 1
maxWorkers: 1
responseTimeout: 1500

handler:
    model_name: "meta-llama/Llama-2-7b-hf"
    quantized_model_path: "best_model.pt"
    example_inputs_mode: "MASK_KV_POS"
    to_channels_last: false

    # generation params 
    batch_size: 1
    max_context_length: 2048
    input_tokens: 1024 
    max_new_tokens: 128 
    
    # use bf16-int8 mix
    quant_with_amp: true
    
    # SQ quantization params
    ipex_smooth_quantization: true 
    calibration_dataset: "NeelNanda/pile-10k"
    calibration_split: "train"
    num_calibration_iters: 32
    alpha: 0.9

    # decoding technique 
    greedy: true
    
